{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» <a class = 'tocSkip'>\n",
    "\n",
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "В проекте будет обучена модель классификации комментариев на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок. Значение метрики качества *F1* должно быть не меньше 0.75. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Загрузка и подготовка данных.\n",
    "\n",
    "Выведем общую информацию о ДатаСете, проверим на наличие критичных ошибок, а также оценим насколько сбалансированы классы целевого признака. Так как моделям машинного обучения предстоит работать с текстами, даже при отсутствии критичных ошибок в данных понадобится дополнительная предобработка датасета.\n",
    "\n",
    "### 1.1. Общая информация о датасете.\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак. Импортируем библиотеки, посмотрим на наш датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n",
      "Информация о Датасете: None\n",
      "Количество дублей: 0\n",
      "---------------------------------------------------\n",
      "Соотношение позитивных и негативных комментариев:\n",
      "Положительные: 143346 или 89.8 %\n",
      "Негативные: 16225 или 10.2 %\n",
      "---------------------------------------------------\n",
      "Общий вид таблицы:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159566  \":::::And for the second time of asking, when ...      0\n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159569  And it looks like it was actually you who put ...      0\n",
       "159570  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159571 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Импорт библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# Импорт отдельных методов\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Отключаем уведомления об ошибках.\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Открываем файл, выводим общую информацию.\n",
    "data = pd.read_csv('datasets/toxic_comments.csv')\n",
    "print('Информация о Датасете:', data.info())\n",
    "print('Количество дублей:', data.duplicated().sum())\n",
    "print('---------------------------------------------------')\n",
    "print('Соотношение позитивных и негативных комментариев:')\n",
    "print('Положительные:', data['toxic'].value_counts()[0], 'или', \n",
    "      (data['toxic'].value_counts()[0] / data.shape[0]).round(3)*100, '%')\n",
    "print('Негативные:', data['toxic'].value_counts()[1], 'или', \n",
    "      (data['toxic'].value_counts()[1] / data.shape[0]).round(3)*100, '%')\n",
    "print('---------------------------------------------------')\n",
    "print('Общий вид таблицы:')\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С данными в целом всё в порядке - пропусков и дублей нет, сама структура таблицы лаконична и понятна, но лишь для человека, а для работы моделей машинного обучения дополнительная предобработка всё равно потребуется. Единственный недостаток (или скорее особенность) в данных - целевой признак не сбалансирован, будем учитывать это при разделении выборок на обучающую и тестовую. Можем переходить к следующему этапу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Преобразование данных\n",
    "\n",
    "Перед тем как передать данные в виде признаков для машинного обучения, эти данные необходимо дополнительно упростить и преобразовать. \n",
    "\n",
    " 1. Потребуется провести Лемматизацию (с английским текстом поможет WordNetLemmatizer)\n",
    " 2. От лишних символов текст очистят регулярные выражения (и соответствующая библиотека re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Andrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Andrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вид новой таблицы:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>D aww He match this background colour I m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man I m really not trying to edit war It s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>More I can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>And for the second time of asking when your vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>You should be ashamed of yourself That is a ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Spitzer Umm there no actual article for prosti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>And it look like it wa actually you who put on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>And I really don t think you understand I came...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "0       Explanation\\nWhy the edits made under my usern...      0   \n",
       "1       D'aww! He matches this background colour I'm s...      0   \n",
       "2       Hey man, I'm really not trying to edit war. It...      0   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4       You, sir, are my hero. Any chance you remember...      0   \n",
       "...                                                   ...    ...   \n",
       "159566  \":::::And for the second time of asking, when ...      0   \n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0   \n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0   \n",
       "159569  And it looks like it was actually you who put ...      0   \n",
       "159570  \"\\nAnd ... I really don't think you understand...      0   \n",
       "\n",
       "                                                lemm_text  \n",
       "0       Explanation Why the edits made under my userna...  \n",
       "1       D aww He match this background colour I m seem...  \n",
       "2       Hey man I m really not trying to edit war It s...  \n",
       "3       More I can t make any real suggestion on impro...  \n",
       "4       You sir are my hero Any chance you remember wh...  \n",
       "...                                                   ...  \n",
       "159566  And for the second time of asking when your vi...  \n",
       "159567  You should be ashamed of yourself That is a ho...  \n",
       "159568  Spitzer Umm there no actual article for prosti...  \n",
       "159569  And it look like it wa actually you who put on...  \n",
       "159570  And I really don t think you understand I came...  \n",
       "\n",
       "[159571 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 52.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Создаём функцию очистки текста при помощи регулярных выражений, а также добавления лемматизации.\n",
    "def clear_and_lemm(text):\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text) \n",
    "    clear_text = \" \".join(text.split())\n",
    "    lemm_list = [lemmatizer.lemmatize(word) for word in clear_text.split()]\n",
    "    clear_and_lemm_text = \" \".join(lemm_list)  \n",
    "    return clear_and_lemm_text\n",
    "\n",
    "# Загрузка слов из библиотеки nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Применение функции\n",
    "data['lemm_text'] = data['text'].apply(clear_and_lemm)\n",
    "print('Вид новой таблицы:')\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Текст очищен и лемматизирован, но работа с данными ещё не завершена - дополнительные манипуляции будут разными для разных моделей, поэтому производить их будем уже в рамках обучения, к которому сейчас и перейдём."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Обучение и проверка моделей.\n",
    "\n",
    "Так как в нашем распоряжении достаточно большое количество наблюдений (комментариев), а признаки представляют собой наборы текста, работа с которыми относительно ресурсозатратна - обучение и тестирование моделей будет происходить в два этапа.\n",
    "\n",
    "1. Сначала проверим общую работоспособность и скорость моделей без тюнинга гиперпараметров. Это позволит оценить номинальную скорость моделей, и соответственно - потенциал \n",
    "2. Подбор гиперпараметров и финальное тестирование.\n",
    "\n",
    "### 2.1. Разделение выборок, запуск моделей без подбора гиперпараметров.\n",
    "\n",
    "Сразу разделим датасет на обучающую и тестовую выборку, не забудем указать параметр stratify, чтобы учесть дисбаланс классов. Модели будут обучаться и подбирать параметры на обучающей выборке. Вместе с тем будем сразу проверять результат, делая предсказания на тестовой выборке.\n",
    "\n",
    "Весь процесс будет протекать внутри заранее написанной функции поиска по сетке, которая будет подготовлена уже перед пробными запусками моделей, но на первом этапе будем передавать в функцию пустую сетку параметров. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Оставим 10 % всех комментариев для тестовой выборки.\n",
    "train, test = train_test_split(data, test_size = 0.1, random_state = 321, stratify = data['toxic'])\n",
    "\n",
    "# Определяем признаки\n",
    "X_train = train['lemm_text'].values.astype('U')\n",
    "y_train = train['toxic']\n",
    "\n",
    "# \"Истинными\" значениями будут значения целевого признака в тестовой выборке (y_test) \n",
    "y_true = test['toxic']\n",
    "\n",
    "# Создание списка стоп-слов, счётчика с со стоп словами \n",
    "stop_words = set(stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stop_words)\n",
    "\n",
    "# Посчитаем TF-IDF для X_train и X_test, вызовем функцию fit_transform():\n",
    "tf_idf_train = count_tf_idf.fit_transform(X_train)\n",
    "tf_idf_test = count_tf_idf.transform(test['lemm_text'].values.astype('U'))\n",
    "\n",
    "# Создаём функцию для GridSearch\n",
    "def grid_search(model, param_grid):\n",
    "    \n",
    "    # Задаём сетку GridSearchCV\n",
    "    model_Grid = GridSearchCV(estimator = model, param_grid = param_grid, scoring = 'f1')    \n",
    "    \n",
    "    # Обучение модели, вывод лучших параметров и качества модели\n",
    "    model_Grid.fit(tf_idf_train, y_train)    \n",
    "    print('Оптимальные параметры модели:')\n",
    "    display(model_Grid.best_params_)\n",
    "    print('Качество модели после обучения:', model_Grid.best_score_)\n",
    "    predictions = model_Grid.predict(tf_idf_test)\n",
    "    print('F1-score на тестовой выборке:', f1_score(y_true, predictions))\n",
    "    \n",
    "# Пустая сетка параметров\n",
    "param_grid = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print('Логистическая регрессия.')\n",
    "model1 = LogisticRegression()\n",
    "grid_search(model1, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier\n",
      "Оптимальные параметры модели:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество модели после обучения: 0.7413437907574343\n",
      "F1-score на тестовой выборке: 0.7511737089201878\n",
      "Wall time: 2min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('LGBMClassifier')\n",
    "model2 = LGBMClassifier()\n",
    "grid_search(model2, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При попытке обучить CatBoost на тех же подготовленных признаках, что и предыдущие модели, ядро Jupyter Notebook падает, поэтому для CatBoost будут созданы отдельные типы данных Pool (для тестовой и для обучающей выборки)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoostClassifier\n",
      "F1-score на тестовой выборке: 0.700525394045534\n",
      "Wall time: 25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('CatBoostClassifier')\n",
    "y_train_cb, X_train_cb = train['toxic'], train.drop(['toxic', 'lemm_text'], axis=1)\n",
    "y_test_cb, X_test_cb = test['toxic'], test.drop(['toxic', 'lemm_text'], axis=1)\n",
    "\n",
    "train_pool = Pool(data=X_train_cb, label=y_train_cb, text_features=['text'])\n",
    "test_pool = Pool(data=X_test_cb, label=y_test_cb, text_features=['text'])\n",
    "\n",
    "model3 = CatBoostClassifier(task_type='GPU', \n",
    "                            devices='0:1', \n",
    "                            verbose=False).fit(train_pool)\n",
    "\n",
    "print('F1-score на тестовой выборке:', f1_score(y_true, model3.predict(test_pool)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "Был принудтельно прерван после 30 минут неуспешной работы.\n",
      "Wall time: 1e+03 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('RandomForestClassifier')\n",
    "#model4 = RandomForestClassifier()\n",
    "#grid_search(model4, param_grid)\n",
    "print('Был принудтельно прерван после 30 минут неуспешной работы.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоги по моделям следующие:\n",
    "\n",
    " - **Логистическая регрессия** традиционно стала наиболее быстрым вариантом. Ко всему прочему она показала неплохое качество, и почти сразу дотянула до требуемого качества. После подбора гиперпараметров наверняка получится добиться необходимого уровня метрики F1.\n",
    " - **LGBM** был менее расторопным на пустой сетке, но уже смог преодолеть отметку F1-score 0.75. Попробуем закрепить результат, и немного пройдёмся по сетке параметров.\n",
    " - **CatBoost** продемонстрировал наименьшее качество, но благодаря простой возможности использовать GPU обучился намного быстрее своего конкурента по градиентному бустингу. Попробуем подобрать для него параметры, тем более скорость позволяет это сделать.\n",
    " - **Случайный лес** показал неприлично долгое время работы, и после получаса незавершенной работы на пустой сетке был принудительно прерван - тут о поиске гиперпараметров даже не приходится говорить. В следующий этап модель не проходит."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Подбор гиперпараметров.\n",
    "\n",
    "Попробуем улучшить полученные результаты путём подбора гиперпараметров для моделей. В этом процессе будет использоваться GridSearch.\n",
    "\n",
    "Для логистической регрессии и CatBoost можно по сетке перебрать относительно большое количество гиперпараметров - регрессия самая по себе быстро обучается, а у CatBoost'а есть простая возможность производить обучение на GPU. Для LGBMClassifier тоже попробуем улучшить результат, но параметров будет меньше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия.\n",
      "Оптимальные параметры модели:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество модели после обучения: 0.7655294554223555\n",
      "F1-score на тестовой выборке: 0.7830578512396694\n",
      "Wall time: 7min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('Логистическая регрессия.')\n",
    "param_grid1 = [\n",
    "    {'penalty': ['l1'], 'solver': ['newton-cg'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
    "    {'penalty': ['l2'], 'solver': ['lbfgs', 'liblinear', 'sag', 'saga'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "]\n",
    "grid_search(model1, param_grid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier\n",
      "Оптимальные параметры модели:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'n_estimators': 500}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество модели после обучения: 0.7727236294046722\n",
      "F1-score на тестовой выборке: 0.794950528829751\n",
      "Wall time: 26min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('LGBMClassifier')\n",
    "param_grid2 = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'learning_rate' : [0.1, 0.5, 1],\n",
    "}\n",
    "grid_search(model2, param_grid2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По неизвестной причине CatBoost при попытке произвести поиск по сетке через собственный метод grid_search падает с ошибкой (ошибка возникает только при использовании GPU, на CPU всё в порядке - но поиск происходит долго). Не самым элегантным, но более эффективным образом осуществим ручной перебор параметров в цикле."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoostClassifier\n",
      "\n",
      "При параметрах: {'iterations': 500, 'learning_rate': 0.1, 'depth': 6, 'l2_leaf_reg': 1, 'verbose': False, 'task_type': 'GPU', 'devices': '0:1'} метрика F1 улучшилась\n",
      "F1-score на тестовой выборке: 0.7047685834502103\n",
      "\n",
      "При параметрах: {'iterations': 500, 'learning_rate': 0.1, 'depth': 9, 'l2_leaf_reg': 1, 'verbose': False, 'task_type': 'GPU', 'devices': '0:1'} метрика F1 улучшилась\n",
      "F1-score на тестовой выборке: 0.7104895104895104\n",
      "\n",
      "При параметрах: {'iterations': 500, 'learning_rate': 0.1, 'depth': 12, 'l2_leaf_reg': 5, 'verbose': False, 'task_type': 'GPU', 'devices': '0:1'} метрика F1 улучшилась\n",
      "F1-score на тестовой выборке: 0.7157378198387663\n",
      "Wall time: 32min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('CatBoostClassifier')\n",
    "\n",
    "# Задаём начальные переменные f1_score\n",
    "f1_score_current = 0\n",
    "f1_score_best = 0.7\n",
    "\n",
    "# Задаём сетки для разных гиперпараметров\n",
    "learning_rate_list = [0.1, 0.5, 1]\n",
    "depth_list = [3, 6, 9, 12]\n",
    "l2_leaf_reg_list = [1, 3, 5, 7, 9]\n",
    "\n",
    "for l2 in l2_leaf_reg_list:\n",
    "    for lr in learning_rate_list:\n",
    "        for d in depth_list:\n",
    "            model3 = CatBoostClassifier(task_type='GPU', devices='0:1', verbose=False, iterations = 500,\n",
    "                                        learning_rate = lr, depth = d, l2_leaf_reg = l2).fit(train_pool)\n",
    "            f1_score_current = f1_score(y_true, model3.predict(test_pool))                            \n",
    "            if f1_score_current > f1_score_best:\n",
    "                f1_score_best = f1_score_current\n",
    "                print('')\n",
    "                print('При параметрах:', model3.get_params(), 'метрика F1 улучшилась')\n",
    "                print('F1-score на тестовой выборке:', f1_score_current)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбранные модели логистической регрессии, LGBM, CatBoost и случайного леса, уже \"из коробки\" показали неплохие результаты не смотря на дисбаланс классов. Единственная откровенно **неудачная модель - случайный лес**, который оказался крайне медлительным и неэффективны для задачи классификации текстов.\n",
    "\n",
    "А вот для остальных моделей, подбор гиперпараметров помог закрепить результат и повысить качество ещё на несколько пунктов. Правда **CatBoost так и не смог преодолеть необохдимый порог F1-меры** не меньше 0.75. Возможно сказалось сниженное количество итераций, возможно неэффективен перебор в цикле, возможно просто не угадали с набором параметров - сказать наверняка сложно, но к счастью есть другие модели.\n",
    "\n",
    "**Лучшее качество показал LGBMClassifier** - показатель F1-меры достиг 0.77 при обучении и 0.79 на тестовой выборке. Скорость модели получилась выше, чем у CatBoost'а (правда и параметров было меньше), но стоит помнить - работала модель на CPU, а ведь потенциально её можно запустить и на GPU.\n",
    "\n",
    "**Логистическая регрессия** не сильно отстала в качестве от градиентных бустингов, и также преодолела необходимый порог, при этом оказалась в 3 раза быстрее, так что если в приоритете оперативность - **вариант тоже отличный.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
