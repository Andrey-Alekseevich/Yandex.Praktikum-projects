{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отток клиентов банка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основе исторических данных о поведении клиентов банка необходимо спрогнозировать значение целевого признака - уйдёт клиент из банка в ближайшее время или нет.\n",
    "\n",
    "Основная задача - найти и построить модель с предельно большим значением *F1*-меры. Выбранную нужно довести метрику до 0.59.\n",
    "\n",
    "Дополнительно измерим *AUC-ROC*, сравнивним её значение с *F1*-мерой.\n",
    "\n",
    "Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)\n",
    "\n",
    "## План действий:\n",
    "\n",
    "### [1. Изучение общей информации о данных](#intro)\n",
    " - [Первичный просмотр данных](#start)\n",
    " - [Предобработка данных](#prepare)\n",
    "\n",
    "### [2. Исследование задачи](#task)\n",
    " - [Модель логистической регрессии.](#LogisticRegression)\n",
    " - [Модель случайного леса.](#RandomForestClassifier)\n",
    " - [Catboost classifier.](#Catboost)\n",
    "\n",
    "### [3. Борьба с дисбалансом](#balance)\n",
    " - [Изменение параметра weight](#weight)\n",
    " - [Увеличение выборки](#upsample)\n",
    " - [Уменьшение выборки](#downsample)\n",
    "\n",
    "### [4. Тестирование модели](#test)\n",
    " - [ROC-curve (и метрика AUC-ROC)](#auc-roc)\n",
    "\n",
    "### [Общий вывод](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Изучение общей информации о данных <a id=\"intro\"></a>\n",
    "Осуществляем загрузку и подготовку данных.\n",
    "\n",
    "## Первичный просмотр данных <a id=\"start\"></a>\n",
    "Проверим какие форматы используются в данных, а также проверим их на наличие пропущенных значений. В столбце CustomerId должны быть уникальные значения исходя из описания данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             9091 non-null float64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество дублей: 0\n",
      "Количество дублей в столбце CustomerId: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Импортируем...\n",
    "\n",
    "# ...основные библиотеки,\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ... методы обрбаотки, подготовки и вывода данных,\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from catboost.utils import get_roc_curve\n",
    "\n",
    "# ...модели и их метрики.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.metrics import accuracy_score, f1_score, auc, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# В процессе  могу появиться некритичные ошибки. Скроем их.\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Открываем файл, выводим основную информацию по нему\n",
    "data = pd.read_csv('/datasets/Churn.csv')\n",
    "display(data.info())\n",
    "print('Количество дублей:', data.duplicated().sum())\n",
    "print('Количество дублей в столбце CustomerId:', data.duplicated(subset = ['CustomerId']).sum())\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть пропущенные значения в столбце Tenure — не во всех случаях известно количество недвижимости у клиента. Этот же столбец по смыслу указанных в нём данных должен иметь целочисленный формат. В остальном данные отражены корректно и в полном объёме. \n",
    "Правда если смотреть с точки зрения готовности данных для обучения моделей - то в данном случае есть необходимость в дополнительной предобработке, которую мы и осуществим."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных <a id=\"prepare\"></a>\n",
    "\n",
    "Из таблицы мы уберём колонки, которые не влияют на целевые признаки, и будут лишь добавлять шум в обучение моделей. Такие признаки как: номер столбца, ID пользователя и его имя, едва ли влияют на решение об отказе от использования продуктов - при их обработке модель будет учиться искать взаимосвязи там, где их нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Уберём ненужные колонки\n",
    "data = data.drop(columns=['RowNumber', 'CustomerId', 'Surname'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ко всему датафрейму применим технику One-Hot Encoding для преобразования категориальных переменных в численные (их всего две). Передадим аргумент drop_first=True, чтобы не попасть в дамми-ловушку. А столбец с данными о количестве недвижимости у клиента  заполним их медианной, чтобы избавить его от пропущенных значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропущенных значений в столбце Tenure: 0\n"
     ]
    }
   ],
   "source": [
    "# Применим технику One-Hot Encoding\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "# Заполним пропущенные значения в столбце 'Tenure'\n",
    "data['Tenure'] = data['Tenure'].fillna(data['Tenure'].median())\n",
    "\n",
    "# Проверим заполнение пропусков\n",
    "print('Количество пропущенных значений в столбце Tenure:', data['Tenure'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных присутствуют количественные признаки с разным разбросом значений. Вполне возможно, что для более качественного применения машинного обучения потребуется дополнительная предобработка путём стандартизации данных. Создадим дополнительный DataFrame на этот случай, но только после того как \"отрежем\" часть данных для тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение выборок с применением стратификации (на тестовую и обучающую)\n",
    "data, data_test = train_test_split(data, test_size=0.1, random_state=12345, stratify=data['Exited'])\n",
    "\n",
    "# Стандартизируем данные \n",
    "features_values = data.drop(['Exited'], axis=1)\n",
    "scaled_values = StandardScaler().fit_transform(features_values.values)\n",
    "scaled_data = pd.DataFrame(scaled_values, index=features_values.index, columns=features_values.columns)\n",
    "scaled_data['Exited'] = data['Exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что в итоге получилось после предобработки данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Стандартизированный DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8834</td>\n",
       "      <td>0.073807</td>\n",
       "      <td>-0.469049</td>\n",
       "      <td>-0.727682</td>\n",
       "      <td>0.490126</td>\n",
       "      <td>-0.911343</td>\n",
       "      <td>0.647388</td>\n",
       "      <td>-1.030693</td>\n",
       "      <td>0.931003</td>\n",
       "      <td>-0.579061</td>\n",
       "      <td>-0.574442</td>\n",
       "      <td>0.912685</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9524</td>\n",
       "      <td>2.071453</td>\n",
       "      <td>-0.087657</td>\n",
       "      <td>-0.002257</td>\n",
       "      <td>1.125440</td>\n",
       "      <td>-0.911343</td>\n",
       "      <td>0.647388</td>\n",
       "      <td>-1.030693</td>\n",
       "      <td>-0.382992</td>\n",
       "      <td>1.726934</td>\n",
       "      <td>-0.574442</td>\n",
       "      <td>0.912685</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7723</td>\n",
       "      <td>0.425724</td>\n",
       "      <td>-0.373701</td>\n",
       "      <td>0.360456</td>\n",
       "      <td>-1.227826</td>\n",
       "      <td>0.808172</td>\n",
       "      <td>-1.544670</td>\n",
       "      <td>0.970221</td>\n",
       "      <td>1.350476</td>\n",
       "      <td>-0.579061</td>\n",
       "      <td>1.740819</td>\n",
       "      <td>0.912685</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2553</td>\n",
       "      <td>0.798342</td>\n",
       "      <td>3.058828</td>\n",
       "      <td>1.085881</td>\n",
       "      <td>-1.227826</td>\n",
       "      <td>-0.911343</td>\n",
       "      <td>0.647388</td>\n",
       "      <td>0.970221</td>\n",
       "      <td>1.705072</td>\n",
       "      <td>-0.579061</td>\n",
       "      <td>1.740819</td>\n",
       "      <td>0.912685</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1687</td>\n",
       "      <td>2.071453</td>\n",
       "      <td>-0.183005</td>\n",
       "      <td>-0.364969</td>\n",
       "      <td>0.972274</td>\n",
       "      <td>-0.911343</td>\n",
       "      <td>0.647388</td>\n",
       "      <td>0.970221</td>\n",
       "      <td>-1.241355</td>\n",
       "      <td>-0.579061</td>\n",
       "      <td>1.740819</td>\n",
       "      <td>0.912685</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age    Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "8834     0.073807 -0.469049 -0.727682  0.490126      -0.911343   0.647388   \n",
       "9524     2.071453 -0.087657 -0.002257  1.125440      -0.911343   0.647388   \n",
       "7723     0.425724 -0.373701  0.360456 -1.227826       0.808172  -1.544670   \n",
       "2553     0.798342  3.058828  1.085881 -1.227826      -0.911343   0.647388   \n",
       "1687     2.071453 -0.183005 -0.364969  0.972274      -0.911343   0.647388   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
       "8834       -1.030693         0.931003          -0.579061        -0.574442   \n",
       "9524       -1.030693        -0.382992           1.726934        -0.574442   \n",
       "7723        0.970221         1.350476          -0.579061         1.740819   \n",
       "2553        0.970221         1.705072          -0.579061         1.740819   \n",
       "1687        0.970221        -1.241355          -0.579061         1.740819   \n",
       "\n",
       "      Gender_Male  Exited  \n",
       "8834     0.912685       0  \n",
       "9524     0.912685       0  \n",
       "7723     0.912685       0  \n",
       "2553     0.912685       1  \n",
       "1687     0.912685       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Предобработанный DataFrame без стандартизации:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8834</td>\n",
       "      <td>657</td>\n",
       "      <td>34</td>\n",
       "      <td>3.0</td>\n",
       "      <td>107136.60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>153895.46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9524</td>\n",
       "      <td>850</td>\n",
       "      <td>38</td>\n",
       "      <td>5.0</td>\n",
       "      <td>146756.68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>78268.61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7723</td>\n",
       "      <td>691</td>\n",
       "      <td>35</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178038.17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2553</td>\n",
       "      <td>727</td>\n",
       "      <td>71</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>198446.91</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1687</td>\n",
       "      <td>850</td>\n",
       "      <td>37</td>\n",
       "      <td>4.0</td>\n",
       "      <td>137204.77</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28865.59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "8834          657   34     3.0  107136.60              1          1   \n",
       "9524          850   38     5.0  146756.68              1          1   \n",
       "7723          691   35     6.0       0.00              2          0   \n",
       "2553          727   71     8.0       0.00              1          1   \n",
       "1687          850   37     4.0  137204.77              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "8834               0        153895.46       0                  0   \n",
       "9524               0         78268.61       0                  1   \n",
       "7723               1        178038.17       0                  0   \n",
       "2553               1        198446.91       1                  0   \n",
       "1687               1         28865.59       0                  0   \n",
       "\n",
       "      Geography_Spain  Gender_Male  \n",
       "8834                0            1  \n",
       "9524                0            1  \n",
       "7723                1            1  \n",
       "2553                1            1  \n",
       "1687                1            1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Размеры выборок:\n",
      "Обучающая + Валидационная (ДатаФрейм data): 9000\n",
      "Тестовая: 1000\n",
      "\n",
      "Процент ушедших клиентов в выборках\n",
      "В обучающей и валидационной: 20.37%\n",
      "В тестовой выборке: 20.40%\n"
     ]
    }
   ],
   "source": [
    "# Выведем предобработанные данные\n",
    "print('Стандартизированный DataFrame:')\n",
    "display(scaled_data.head())\n",
    "print('')\n",
    "print('Предобработанный DataFrame без стандартизации:')\n",
    "display(data.head())\n",
    "print('')\n",
    "\n",
    "# Выводем информацию о полученных выборках\n",
    "print('Размеры выборок:')\n",
    "print('Обучающая + Валидационная (ДатаФрейм data):', data.shape[0])\n",
    "print('Тестовая:', data_test.shape[0])\n",
    "print('')\n",
    "print('Процент ушедших клиентов в выборках')\n",
    "print('В обучающей и валидационной: {:.2%}' .format(data.query('Exited == 1').shape[0] / data.shape[0]))\n",
    "print('В тестовой выборке: {:.2%}'.format(data_test.query('Exited == 1').shape[0] / data_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Итоги по первому пункту:**\n",
    "Данные предобработаны. На всякий случай оставили два датафрейма - в одном из них данные были стандартизированы. Проверим насколько наши модели нуждаются в подобном шаге (во многих моделях этот процесс должен быть предусмотрен по умолчанию). \n",
    "\n",
    "Уже на этапе изучениия данных можно сделать вывод насколько классы не сбалансированы - в целевом признаке примерно в 20 % случаев встречается класс \"1\" (клиент ушёл из банка), и почти в 80 % класс \"0\" (клиент не ушёл из банка). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Исследование задачи <a id=\"task\"></a>\n",
    "Пока что не будем принимать во внимание факт различия объемов классов почти в 4 раза, и проведём исследование задачи и обучение модели без учёта дисбаланса. \n",
    "\n",
    "Рассматривать будем три основных модели:\n",
    " 1. [Модель логистической регрессии.](#LogisticRegression)\n",
    " 2. [Модель случайного леса.](#RandomForestClassifier)\n",
    " 3. [Catboost classifier.](#Catboost)\n",
    " \n",
    "Для каждой модели посчитаем качество модели (ориентироваться будем на F1-меру). Данные выведем по обучающей и валидационной выборке, чтобы оценить переобучаемость моделей. Дополнительно оценим общее время работы функций обучения моделей, и вывода метрики по ним.\n",
    " \n",
    "Так как по ходу проекта нам понадобится менять данные перед обучением моделей (при балансировке), обучение и вывод метрик будем проводить внутри функций. Дополнительно напишем функцию для выделения в выборках столбцов с целевыми и нецелевыми признаками). Сами выборки (обучающую и валидационную) определим сразу, и будем передавать их в функции.\n",
    "\n",
    "В конце попробуем [обучить наши модели на стандартизированных данных](#Scaled_fit), проверим насколько этот процесс будет полезен для улучшения качества. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размеры выборок:\n",
      "Обучающая: 8100\n",
      "Валидационная: 900\n",
      "\n",
      "Процент ушедших клиентов в выборках\n",
      "В обучающей выборки: 20.37%\n",
      "В валидационной выборке: 20.33%\n"
     ]
    }
   ],
   "source": [
    "# Напишем функцию выделения в выборках столбцов с целевыми и нецелевыми признаками.\n",
    "def split_data(data_train, data_valid, target):\n",
    "\n",
    "    features_train = data_train.drop([target], axis=1)\n",
    "    target_train = data_train[target]\n",
    "    \n",
    "    features_valid = data_valid.drop([target], axis=1)\n",
    "    target_valid = data_valid[target]\n",
    "    \n",
    "\n",
    "    return target_train, features_train, target_valid, features_valid\n",
    "\n",
    "# Определим обучающую и валидационную выборки и выведем их размеры\n",
    "data_train, data_valid = train_test_split(data, test_size=0.1, random_state=12345, stratify=data['Exited'])\n",
    "print('Размеры выборок:')\n",
    "print('Обучающая:', data_train.shape[0])\n",
    "print('Валидационная:', data_valid.shape[0])\n",
    "print('')\n",
    "print('Процент ушедших клиентов в выборках')\n",
    "print('В обучающей выборки: {:.2%}' .format(data_train.query('Exited == 1').shape[0] / data_train.shape[0]))\n",
    "print('В валидационной выборке: {:.2%}'.format(data_valid.query('Exited == 1').shape[0] / data_valid.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Модель логистической регрессии <a id=\"LogisticRegression\"></a>\n",
    "\n",
    "В логистической регрессии поменяем только гиперпараметр solver - в прошлом проекте значение 'newton-cg' в нём позволило поднять точность модели. При необходимости в функцию можно будет передать модель с другими гиперпараметрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера модели на валидационной выборке: 0.308\n",
      "F1-мера модели на тренировочной выборке: 0.321\n",
      "ROC-AUC, полученный на валидационной выборке: 0.585\n",
      "\n",
      "Время выполнения кода:\n",
      "CPU times: user 4.31 s, sys: 5.15 s, total: 9.46 s\n",
      "Wall time: 9.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Напишем функцию обучения и тестирования модели.\n",
    "def model1_def (data_train, data_valid, target, model):\n",
    "    target_train, features_train, target_valid, features_valid = split_data(data_train, data_valid, target)\n",
    "    model.fit(features_train, target_train)\n",
    "    valid_predictions = model.predict(features_valid)\n",
    "    train_predictions = model.predict(features_train)\n",
    "    print('F1-мера модели на валидационной выборке: {:.3f}' .format(f1_score(target_valid, valid_predictions)))\n",
    "    print('F1-мера модели на тренировочной выборке: {:.3f}' .format(f1_score(target_train, train_predictions)))\n",
    "    print('ROC-AUC, полученный на валидационной выборке: {:.3f}' .format(roc_auc_score(target_valid, valid_predictions)))\n",
    "    print('')\n",
    "\n",
    "\n",
    "# Зададим параметры модели, и применим функцию\n",
    "model1 = LogisticRegression(random_state=12345, solver='newton-cg')\n",
    "model1_def (data_train, data_valid, 'Exited', model1)\n",
    "print('Время выполнения кода:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество получилось совсем низким, и вряд ли его получится существенно поднять только изменением гиперпараметров - здесь нужны более радикальные меры. Пока отложим логистическую регрессию и посмотрим на другие модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Модель случайного леса <a id=\"RandomForestClassifier\"></a>\n",
    "\n",
    "У модели случайного леса сделаем перебор гиперпараметров n_estimators и max_depth в цикле, чтобы найти наиболее качественную модель. В зависимости от аргумента \"result\" функция будет либо просто выводить параметры и значение F1-меры наилучшей модели, либо саму модель (для дальнейшего использования)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимальные параметры:\n",
      "Оптимальное количество деревьев: 40\n",
      "Лучшая глубина дерева: 9\n",
      "\n",
      "F1-мера модели на валидационной выборке: 0.566\n",
      "F1-мера модели на тренировочной выборке: 0.652\n",
      "ROC-AUC, полученный на валидационной выборке: 0.706\n",
      "\n",
      "Время выполнения кода:\n",
      "CPU times: user 1min 6s, sys: 0 ns, total: 1min 6s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Напишем функцию обучения и тестирования модели.\n",
    "def model2_def (data_train, data_valid, target, result):\n",
    "    \n",
    "    # Определение переменных и выборок\n",
    "    target_train, features_train, target_valid, features_valid = split_data(data_train, data_valid, target)\n",
    "    best_est = 0\n",
    "    best_depth = 0\n",
    "    best_f1_score = 0\n",
    "    best_model = None\n",
    "    \n",
    "    # Поиск лучшей модели\n",
    "    for est in range(10, 151, 10):\n",
    "        for depth in range (1, 10):\n",
    "            model = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "            model.fit(features_train, target_train) \n",
    "            valid_predictions = model.predict(features_valid)\n",
    "            f1_score_result = f1_score(target_valid, valid_predictions)\n",
    "            if f1_score_result > best_f1_score:\n",
    "                best_est = est\n",
    "                best_depth = depth\n",
    "                best_f1_score = f1_score_result\n",
    "                best_model = model\n",
    "    \n",
    "    # Вывод полученных результатов или модели, в зависимости от параметра result\n",
    "    if result == 'metrics':\n",
    "        valid_predictions = best_model.predict(features_valid)\n",
    "        train_predictions = best_model.predict(features_train)\n",
    "        print('Оптимальные параметры:')\n",
    "        print('Оптимальное количество деревьев:', best_est)\n",
    "        print('Лучшая глубина дерева:', best_depth)\n",
    "        print('')\n",
    "        print('F1-мера модели на валидационной выборке: {:.3f}' .format(f1_score(target_valid, valid_predictions)))\n",
    "        print('F1-мера модели на тренировочной выборке: {:.3f}' .format(f1_score(target_train, train_predictions)))\n",
    "        print('ROC-AUC, полученный на валидационной выборке: {:.3f}' .format(roc_auc_score(target_valid, valid_predictions)))\n",
    "        print('')\n",
    "    if result == 'model':\n",
    "        return best_model\n",
    "\n",
    "# Применим функцию\n",
    "model2_def (data_train, data_valid, 'Exited', 'metrics')\n",
    "print('Время выполнения кода:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество заметно выше, чем у логистической регрессии, и почти достигло необходимой величины F-меры (0.59), но быстродействие обучения и валидации модели наоборот заметно хуже. \n",
    "\n",
    "Недостаток перебора в цикле - нет возможности передать функции модель с заранее заданными гиперпараметрами - их поиск осуществляется уже в процессе выполнения функции. Проверим альтернативный метод поиска лучшей модели, который лишён этого изъяна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search или поиск по сетке\n",
    "Попробуем сделать код компактнее, а функцию более гибкой, при помощи метода поиска по сетке. Зададим те же параметры, сравним скорость работы. Посмотрим какие гиперпараметры по мнению Grid search являются наилучшими."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимальные параметры:\n",
      "{'max_depth': 10, 'n_estimators': 20}\n",
      "\n",
      "F1-мера модели на валидационной выборке: 0.562\n",
      "F1-мера модели на тренировочной выборке: 0.687\n",
      "ROC-AUC, полученный на валидационной выборке: 0.705\n",
      "\n",
      "Время выполнения кода:\n",
      "CPU times: user 1min 44s, sys: 0 ns, total: 1min 44s\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Напишем функцию для поиска по сетке.\n",
    "def model2_grid_search (data_train, data_valid, target, model, result):\n",
    " \n",
    "    # Зададим параметры для поиска по сетке, определим выборки.\n",
    "    target_train, features_train, target_valid, features_valid = split_data(data_train, data_valid, target)\n",
    "    param_grid2 = {'n_estimators': [int (x) for x in np.arange(start = 10, stop = 151, step = 10)],\n",
    "              'max_depth': [int (x) for x in np.arange(start = 1, stop = 11, step = 1)]}\n",
    "    \n",
    "    # Найдём наилучшие параметры, и обучим по ним модель.\n",
    "    model2_Grid = GridSearchCV(estimator = model, param_grid = param_grid2, cv = 2, scoring = 'f1')\n",
    "    model2_Grid.fit(features_train, target_train)\n",
    "    \n",
    "    # Вывод полученных результатов или модели, в зависимости от параметра result\n",
    "    if result == 'metrics':\n",
    "        print('Оптимальные параметры:')\n",
    "        print(model2_Grid.best_params_)\n",
    "        print('')\n",
    "        valid_predictions = model2_Grid.predict(features_valid)\n",
    "        train_predictions = model2_Grid.predict(features_train)\n",
    "        print('F1-мера модели на валидационной выборке: {:.3f}' .format(f1_score(target_valid, valid_predictions)))\n",
    "        print('F1-мера модели на тренировочной выборке: {:.3f}' .format(f1_score(target_train, train_predictions)))\n",
    "        print('ROC-AUC, полученный на валидационной выборке: {:.3f}' .format(roc_auc_score(target_valid, valid_predictions)))\n",
    "        print('')\n",
    "    if result == 'model':\n",
    "        return model2_Grid\n",
    "\n",
    "# Зададим параметры модели, и применим функцию\n",
    "model2_CV = RandomForestClassifier(random_state = 12345)\n",
    "\n",
    "model2_grid_search (data_train, data_valid, 'Exited', model2_CV, 'metrics')    \n",
    "print('Время выполнения кода:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хоть Grid Search слегка переобучил модель и подобрал другие параметры для модели, качество модели серьёзно не снизилось\n",
    "\n",
    "С точки зрения быстродействия поиск по сетке показал себя менее эффективным по сравнению с перебором в цикле, но сделал функцию намного более гибкой - теперь в неё можно передать \"стартовую модель\", из которой по перебору параметров можно найти (и вернуть при необходимости) лучшую модель. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Catboost classifier <a id=\"Catboost\"></a>\n",
    "\n",
    "Проверим последнюю модель - Catboost. В функции оставим стандартные гиперпараметры - обычно они показывают себя весьма неплохо. Даже если полученное качество будет сильно плохим, у нас будет возможность передать в функцию новую модель, с более подходящими гиперпараметрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая итерация: 102\n",
      "\n",
      "F1-мера модели на валидационной выборке: 0.592\n",
      "F1-мера модели на тренировочной выборке: 0.660\n",
      "ROC-AUC, полученный на валидационной выборке: 0.724\n",
      "\n",
      "\n",
      "Время выполнения кода:\n",
      "CPU times: user 47.1 s, sys: 5.49 s, total: 52.6 s\n",
      "Wall time: 54.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def model3_def (data_train, data_valid, target, model, result):\n",
    "    \n",
    "    # Подготовка выборок\n",
    "    target_train, features_train, target_valid, features_valid = split_data(data_train, data_valid, target)\n",
    "    eval_dataset = Pool(features_valid, target_valid)\n",
    "      \n",
    "    # Обучение и использование модели    \n",
    "    model.fit(X=features_train, y=target_train, silent = True, eval_set=eval_dataset)\n",
    "    \n",
    "    # Вывод полученных результатов или модели, в зависимости от параметра result\n",
    "    if result == 'metrics':\n",
    "        print('Лучшая итерация:', model.get_best_iteration())\n",
    "        print('')\n",
    "        valid_predictions = model.predict(features_valid)\n",
    "        train_predictions = model.predict(features_train)\n",
    "        print('F1-мера модели на валидационной выборке: {:.3f}' .format(f1_score(target_valid, valid_predictions)))\n",
    "        print('F1-мера модели на тренировочной выборке: {:.3f}' .format(f1_score(target_train, train_predictions)))\n",
    "        print('ROC-AUC, полученный на валидационной выборке: {:.3f}' .format(roc_auc_score(target_valid, valid_predictions)))\n",
    "        print('')\n",
    "    if result == 'model':\n",
    "        return model\n",
    "    \n",
    "# Применяем функцию - проверяем качество и быстродействие модели\n",
    "model3 = CatBoostClassifier(random_state=12345, eval_metric='F1')\n",
    "model3_def (data_train, data_valid, 'Exited', model3, 'metrics')\n",
    "print('')\n",
    "print('Время выполнения кода:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый быстрый и самый точный, Catboost - победитель в обучении на несбалансированных выборках. Полученная точность даже преодолела требуемый порог F1-меры. \n",
    "\n",
    "Сделать работу функции ещё быстрее поможет параметр early_stopping_rounds, лучшая итерация всё равно была найдена почти в самом начале, и незачем было проводить ещё почти 900 лишних итераций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение на стандартизированных данных <a id=\"Scaled_fit\"></a>\n",
    "Проведём последний тест на всех трёх моделях - проверим насколько стандартизация числовых признаков помогает моделям в обучении. Для чистоты эксперимента гиперпараметры менять не будем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество модели логистической регрессии\n",
      "F1-мера модели на валидационной выборке: 0.305\n",
      "F1-мера модели на тренировочной выборке: 0.328\n",
      "ROC-AUC, полученный на валидационной выборке: 0.582\n",
      "\n",
      "--------------------------------------------------\n",
      "Качество модели случайного леса\n",
      "Оптимальные параметры:\n",
      "Оптимальное количество деревьев: 40\n",
      "Лучшая глубина дерева: 9\n",
      "\n",
      "F1-мера модели на валидационной выборке: 0.566\n",
      "F1-мера модели на тренировочной выборке: 0.653\n",
      "ROC-AUC, полученный на валидационной выборке: 0.706\n",
      "\n",
      "--------------------------------------------------\n",
      "Качество Catboost\n",
      "Лучшая итерация: 102\n",
      "\n",
      "F1-мера модели на валидационной выборке: 0.592\n",
      "F1-мера модели на тренировочной выборке: 0.660\n",
      "ROC-AUC, полученный на валидационной выборке: 0.724\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Определим обучающую и валидационную выборки для стантдартизированных данных\n",
    "data_train_scaled, data_valid_scaled = train_test_split(scaled_data, test_size=0.1, random_state=12345, stratify=data['Exited'])\n",
    "\n",
    "print('Качество модели логистической регрессии')\n",
    "model1_def (data_train_scaled, data_valid_scaled, 'Exited', model1)\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "print('Качество модели случайного леса')\n",
    "model2_def (data_train_scaled, data_valid_scaled, 'Exited', 'metrics')\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "print('Качество Catboost')\n",
    "model3_def (data_train_scaled, data_valid_scaled, 'Exited', model3, 'metrics')\n",
    "print('--------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Итоги по второму пункту:**\n",
    "Положительного воздействия на обучаемость моделей стандартизация совсем не оказала (у регресии качество даже наоборот чуть-чуть снизилось). \n",
    "\n",
    "В целом - все рассмотренные модели имеют право на жизнь, и новые попытки обучения уже на сбалансированных данных.\n",
    " - **Логистическая регрессия** оказалась совсем далека от заданной планки качества, да и потенциал улучшения качества тоже низкий - метрика ROC-AUC составила всего 0.58.  При этом модель довольно быстро обучается, поэтому её можно использовать при дальнейшем исследовании, хотя бы для оценки эффективности разных методов предобработки выборок.\n",
    " - **Случайный лес** немного не добрал по качеству, да и быстродействие хуже, чем у остальных, но со счетов списывать его не будем - он может быть более восприимчивым (в хорошем смысле этого слова) к балансировке классов, тем более что метрика ROC-AUC на достойном уровне: 0.70.\n",
    " - **Catboost** явный фаворит и претендент на звание лучшей модели - качество уже лучше, чем у остальных (не только по F1-мере, но и по метрике ROC-AUC). Быстродействие также на отличном уровне (ещё и потенциально может быть улучшено) \n",
    "\n",
    "Попробуем сделать наши модели ещё лучше, перейдём к балансировке классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Борьба с дисбалансом <a id=\"balance\"></a>\n",
    "Улучшим качество моделей, учитывая дисбаланс классов. Обучим разные модели и найдиём лучшую.\n",
    "Сначала попробуем несколько вариантов балансировки выборок, найдём наиболее действенный.\n",
    " - [Изменение параметра weight](#weight)\n",
    " - [Увеличение выборки](#upsample)\n",
    " - [Уменьшение выборки](#downsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Просто добавили ещё один параметр (модели без применения функций) <a id=\"weight\"></a>\n",
    "\n",
    "Начнём с самого простого способа, который доступен для двух наших моделей - простое изменение параметра class_weight (class_weights с указанием новых весов для классов, в случае с Catboost).\n",
    "\n",
    "Как ранее мы успели выяснить - классы отличаются друг от друга примерно в 4 раза, на эту величину мы и будем их балансировать catboost, две другие модели будут балансироваться самостоятельно. Дополнительно ускорим наш CatBoost, и добавим ему early_stopping, чтобы не обучать лишние итерации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество модели логистической регрессии\n",
      "F1-мера модели на валидационной выборке: 0.445\n",
      "F1-мера модели на тренировочной выборке: 0.494\n",
      "ROC-AUC, полученный на валидационной выборке: 0.661\n",
      "\n",
      "--------------------------------------------------\n",
      "Качество модели случайного леста\n",
      "Оптимальные параметры:\n",
      "{'max_depth': 8, 'n_estimators': 90}\n",
      "\n",
      "F1-мера модели на валидационной выборке: 0.588\n",
      "F1-мера модели на тренировочной выборке: 0.691\n",
      "ROC-AUC, полученный на валидационной выборке: 0.760\n",
      "\n",
      "--------------------------------------------------\n",
      "Качество Catboost\n",
      "Лучшая итерация: 10\n",
      "\n",
      "F1-мера модели на валидационной выборке: 0.577\n",
      "F1-мера модели на тренировочной выборке: 0.604\n",
      "ROC-AUC, полученный на валидационной выборке: 0.768\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Качество модели логистической регрессии')\n",
    "model1_weight = LogisticRegression(random_state=12345, solver='newton-cg', class_weight='balanced')\n",
    "model1_def (data_train, data_valid, 'Exited', model1_weight)\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "print('Качество модели случайного леста')\n",
    "model2_weight = RandomForestClassifier(random_state = 12345, class_weight='balanced')\n",
    "model2_grid_search (data_train, data_valid, 'Exited', model2_weight, 'metrics')\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "print('Качество Catboost')\n",
    "model3 = CatBoostClassifier(random_state=12345, eval_metric='F1', early_stopping_rounds = 200)\n",
    "model3_weight = CatBoostClassifier(random_state=12345, eval_metric='F1', class_weights=[1, 4], early_stopping_rounds = 150)\n",
    "model3_def (data_train, data_valid, 'Exited', model3_weight, 'metrics')\n",
    "print('--------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты получились неоднозначными - у логистической регрессии и случайного леса качество выросло (правда не очень сильно), а вот у catboost'качество наоборот снизилось. Попробуем другие методы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Увеличение выборки <a id=\"upsample\"></a>\n",
    "\n",
    "Попробуем вручную произвести балансировку путём увеличения числа строчек, соответствующих классу 1, который в целом встречается в 4 раза реже. Поместим полученнный датасет в новую переменную, после чего передадим её в функции наших моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Новый размер обучающей выборки: 13050\n",
      "Количество ушедших клиентов в увеличенной выборке: 6600\n",
      "Процент ушедших клиентов в увеличенной выборке: 50.57%\n",
      "\n",
      "Качество модели логистической регрессии\n",
      "F1-мера модели на валидационной выборке: 0.447\n",
      "F1-мера модели на тренировочной выборке: 0.705\n",
      "ROC-AUC, полученный на валидационной выборке: 0.664\n",
      "\n",
      "--------------------------------------------------\n",
      "Качество модели случайного леса\n",
      "Оптимальные параметры:\n",
      "Оптимальное количество деревьев: 10\n",
      "Лучшая глубина дерева: 6\n",
      "\n",
      "F1-мера модели на валидационной выборке: 0.610\n",
      "F1-мера модели на тренировочной выборке: 0.795\n",
      "ROC-AUC, полученный на валидационной выборке: 0.784\n",
      "\n",
      "--------------------------------------------------\n",
      "Качество Catboost\n",
      "Лучшая итерация: 484\n",
      "\n",
      "F1-мера модели на валидационной выборке: 0.612\n",
      "F1-мера модели на тренировочной выборке: 0.955\n",
      "ROC-AUC, полученный на валидационной выборке: 0.769\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Напишем функцию увеличения выборки\n",
    "def upsample(data, target, repeat):\n",
    "    zeros = data.loc[data[target] == 0]\n",
    "    ones = data.loc[data[target] == 1]  \n",
    "    upsampled = pd.concat([zeros] + [ones] * repeat)\n",
    "    return upsampled\n",
    "\n",
    "\n",
    "# Применение функции\n",
    "data_train_up = upsample(data_train, 'Exited', 4)\n",
    "\n",
    "# Вывод информации\n",
    "print('Новый размер обучающей выборки:', data_train_up.shape[0])\n",
    "print('Количество ушедших клиентов в увеличенной выборке:', (data_train_up['Exited'] == 1).sum())\n",
    "print('Процент ушедших клиентов в увеличенной выборке: {:.2%}' \n",
    "      .format((data_train_up['Exited'] == 1).sum() / data_train_up.shape[0]))\n",
    "print('')\n",
    "\n",
    "# Проверка апсемпла на моделях\n",
    "print('Качество модели логистической регрессии')\n",
    "model1_def (data_train_up, data_valid, 'Exited', model1)\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "print('Качество модели случайного леса')\n",
    "model2_def (data_train_up, data_valid, 'Exited', 'metrics')\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "print('Качество Catboost')\n",
    "model3_def (data_train_up, data_valid, 'Exited', model3, 'metrics')\n",
    "print('--------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат получился уже лучше, чем при обычной замене гиперпараметров. Логистическая регрессия так и осталась отстающей - случайный лес и Catboost опять оказались сильнее.\n",
    "\n",
    "Получилось выяснить главное - метод апсемпла неплохо справился с задачей улучшения качества наших моделей. Проверим ещё один, очень похожий метод, и можно переходить к финальным тестам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Уменьшение выборки <a id=\"downsample\"></a>\n",
    "Тут всё то же самое - только в обратном направлении, будем уменьшать количество строк с классом 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Новый размер обучающей выборки: 3262\n",
      "Количество ушедших клиентов в увеличенной выборке: 1650\n",
      "Процент ушедших клиентов в увеличенной выборке: 50.58%\n",
      "\n",
      "Качество модели логистической регрессии\n",
      "F1-мера модели на валидационной выборке: 0.449\n",
      "F1-мера модели на тренировочной выборке: 0.716\n",
      "ROC-AUC, полученный на валидационной выборке: 0.666\n",
      "\n",
      "--------------------------------------------------\n",
      "Качество модели случайного леса\n",
      "Оптимальные параметры:\n",
      "Оптимальное количество деревьев: 50\n",
      "Лучшая глубина дерева: 5\n",
      "\n",
      "F1-мера модели на валидационной выборке: 0.594\n",
      "F1-мера модели на тренировочной выборке: 0.784\n",
      "ROC-AUC, полученный на валидационной выборке: 0.775\n",
      "\n",
      "--------------------------------------------------\n",
      "Качество Catboost\n",
      "Лучшая итерация: 60\n",
      "\n",
      "F1-мера модели на валидационной выборке: 0.592\n",
      "F1-мера модели на тренировочной выборке: 0.819\n",
      "ROC-AUC, полученный на валидационной выборке: 0.775\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Напишем функцию увеличения выборки\n",
    "def downsample(data, target, fraction):\n",
    "    zeros = data.loc[data[target] == 0]\n",
    "    ones = data.loc[data[target] == 1]  \n",
    "    downsampled = pd.concat([zeros.sample(frac=fraction, random_state=12345)] + [ones])\n",
    "    return downsampled\n",
    "    \n",
    "# Применение функции\n",
    "data_train_down = downsample(data_train, 'Exited', 0.25)\n",
    "\n",
    "# Вывод информации\n",
    "print('Новый размер обучающей выборки:', data_train_down.shape[0])\n",
    "print('Количество ушедших клиентов в увеличенной выборке:', (data_train_down['Exited'] == 1).sum())\n",
    "print('Процент ушедших клиентов в увеличенной выборке: {:.2%}' \n",
    "      .format((data_train_down['Exited'] == 1).sum() / data_train_down.shape[0]))\n",
    "print('')\n",
    "\n",
    "# Проверка даунсемпла на моделях\n",
    "print('Качество модели логистической регрессии')\n",
    "model1_def (data_train_down, data_valid, 'Exited', model1)\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "print('Качество модели случайного леса')\n",
    "model2_def (data_train_down, data_valid, 'Exited', 'metrics')\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "print('Качество Catboost')\n",
    "model3_def (data_train_down, data_valid, 'Exited', model3, 'metrics')\n",
    "print('--------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Итоги по третьему пункту:**\n",
    "\n",
    "Наилучший эффект дал метод апсемпла - качество (F1-мера и ROC-AUC) улучшилось на всех трёх моделях. У даунсемпла тоже получилось неплохо, но не так хорошо как с апсемплом. А вот изменение гиперпараметров, влияющих на баланс классов, показало себя слабо - качество либо снижалось, либо увеличивалось недостаточно сильно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Тестирование модели <a id=\"test\"></a>\n",
    "\n",
    "Теперь можно проверить на тестовой выборке лучшие модели - случайный лес и catboost, обученных на сбалансированных методом upsample данных.\n",
    "\n",
    "Модель случайного леса мы зададим вручную, так как его оптимальные гиперпараметры нам известны - количество деревьев: 10, лучшая глубина дерева: 6. Нужно будет только повторно обучить его на полных данных, предобработанных при помощи upsample.\n",
    "\n",
    "Оппонента случайного леса будем обучать по-прежнему только на певоначальной обучающей выборке, так catboost сможет ориентироваться на результаты валидационной выборки и не переобучиться - это полезнее, чем получить больший объем обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель случайного леса\n",
      "F1-мера при проверке на тестовой выборке: 0.596\n",
      "----------------------------------------------------------------------------------------\n",
      "Модель Catboost\n",
      "F1-мера при проверке на тестовой выборке: 0.591\n"
     ]
    }
   ],
   "source": [
    "# Определим целевой и остальные признаки для тестовой выборки...\n",
    "features_test = data_test.drop(['Exited'], axis=1)\n",
    "target_test = data_test['Exited']\n",
    "\n",
    "# ...и для новой обучающей выборки (включающей обучающую и валидационную выборки)\n",
    "features_total = data.drop(['Exited'], axis=1)\n",
    "target_total = data['Exited']\n",
    "\n",
    "# Сделаем апсемпл для полных данных\n",
    "data_up = upsample(data, 'Exited', 4)\n",
    "features_total_up = data_up.drop(['Exited'], axis=1)\n",
    "target_total_up = data_up['Exited']\n",
    "\n",
    "# Извлечём и повторно обучим лучшую модель случайного леса\n",
    "best_model_2 = RandomForestClassifier(random_state=12345, n_estimators=10, max_depth=6)\n",
    "best_model_2.fit(features_total_up, target_total_up) \n",
    "\n",
    "# Извлечём уже обученную лучшую модель catboost\n",
    "best_model_3 = model3_def (data_train_up, data_valid, 'Exited', model3, 'model')\n",
    "\n",
    "# Выведем результат\n",
    "print('Модель случайного леса')\n",
    "predictions_model2 = best_model_2.predict(features_test)\n",
    "print('F1-мера при проверке на тестовой выборке: {:.3f}' .format(f1_score(target_test, predictions_model2)))\n",
    "print('----------------------------------------------------------------------------------------')\n",
    "print('Модель Catboost')\n",
    "predictions_model3 = best_model_3.predict(features_test)\n",
    "print('F1-мера при проверке на тестовой выборке: {:.3f}' .format(f1_score(target_test, predictions_model3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обе модели успешно прошли проверку тестовой выборкой! Да, метрика F1 получилась, что называется - \"на грани\", но одна из поставленных в проекте целей - добиться нужно результата при помощи, прежде всего - балансировки классов. Если подобрать правильные гиперпараметры, результат будет лучше.\n",
    "\n",
    "Посмотрим на ещё одну метрику и график, которые дадут нам понимание о качестве модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC-curve (и метрика AUC-ROC) <a id=\"auc-roc\"></a>\n",
    "\n",
    "Чтобы выявить, как сильно наша модель отличается от случайной, построим кривую ROC и посчитаем площадь под ней — получим метрику ROC-AUC.\n",
    "\n",
    "Не смотря на формальное поражение catboost'а в битве моделей, мы будем рассматривать метрику именно для него. Итоговая разница в качестве моделей составляет всего несколько тысячных, а построение ROC-кривой при помощи функции get_roc_curve из модуля utils библиотеки catboost - вариант более удобный. (Да и улучшать качество catboost, при необходимости, проще и быстрее)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Создание пула с тестовыми фичами и таргетом\n",
    "test_pool = Pool(features_test, target_test)\n",
    "\n",
    "# Собираем значения \n",
    "fpr, tpr, _ = get_roc_curve(best_model_3, test_pool)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Построение графика\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.title('Кривая ROC')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения True Positive Rate и False Positive Rate для модели catboost находятся достаточно далеко от линии случайной модели. Исходя из этого можно сделать однозначный вывод - использование модели эффективнее случайного предсказания результатов.\n",
    "\n",
    "Метрика AUC имеет относительно высокое значение, при относительно низком значении F1-меры. Это говорит о не самой успешной работе классификатора в данной конкретной точке (для определенных предсказаний), при этом есть возможность найти порог, для которого результат будет лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итоговый вывод <a id=\"summary\"></a>\n",
    "\n",
    "Лучшими моделями для предсказания намерения клиентов расторгнуть договор с банком стали - случайный лес и catboost. На протяжении всего исследования они показывали примерно равные результаты, и по итогу обе успешно прошли проверку на тестовой выборке, преодолев необходимое значение F1-меры (0.59). \n",
    "\n",
    "Различные методы балансировки классов позволили несколько улучшить качество моделей, но не очень значительно (буквально на несколько сотых значения F1-меры). Вполне возможно, что улучшить результаты поможет подбор других гиперпараметров. Этот факт отчасти подтверждает метрика ROC-AUC, которая находится на относительно высоком уровне (0.84 для catboost).\n",
    "\n",
    "Если выбирать одну конкретную модель для использования - то более интересным вариантом будет catboost. В сравнении с моделью случайного леса, catboost предоставляет возможности для более гибкой настройки, работает ощутимо быстрее, и при этом качество выбранной метрики либо не отличается, либо отличается незначительно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
